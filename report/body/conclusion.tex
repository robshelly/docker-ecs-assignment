\section{Conclusion}
Section one of this paper demonstrated how micro-services can be deployed in a containerised environment using Docker. This was achieved by deploying a messaging system, RabbitMQ, and two services for sending and receiving messages. Containerising services has many benefits including improving scalability.

In the second section of paper the ability to scale and load balance across containers was explored. If this was attempted using the same methods utilised in section one however it would have been much more difficult. This paper used a simple web app to demonstrate scaling. This web app is accessible on port 80. However, when containerised on a single machine, scaling becomes more difficult as scaling the app to add more containers on the machine causes a problem with ports. I.e. two containers cannot both listen on the same port number if they are running on the same machine. This problem would have manifested in section one if the RabbitMQ service was scaled or replicated for redundancy. Two RabbitMQ server containers could not have listened on the same port number!

This problem was overcome by using AWS services to deploy the web app. The app containers were deployed to an ECS instance running and ECS cluster with autoscaling service configured. An application load balancer was then used to balance traffic between the apps running in containers. The apps listen on port 80 of their respective containers  but each container was mapped to an arbitrary port of the host (achieved though simple settings in the task definition). The target group for the ALB takes care of this mapping. It registers the containers on the ECS instance and allows the ALB to route traffic to the host ports for the containers.

The use of these AWS service means that port mapping does not have to be manually configured for the ports as autoscaling occurs. If this system was configured trough the use of Docker alone, as in section one, manual configuration would be necessary.

The third section of paper addressed another issue raised by the deployment of the messaging system. As demonstrated, this required the IP address of the RabbitMQ servers container to be hard-coded into the service that send and receive messages. This is not a satisfactory implementation as it does not allow easy autoscaling. IP addresses hard-coded into the other service would need to be updated every time a RabbitMQ container is created or destroyed.

This issue was overcome through the use of Consul. Consul is a service discovery tool that allows services to communicate by detecting new services/containers as they appear. Services can query the consul server or a consul agent (which runs on services maintaining health checks) when they need to discover other services.

As shown, the use of various tools or service can manage the issues that arise from a simple micro service architecture such as the messaging system demonstrated in section one. This paper demonstrated how the use of the service discovery tool Consul along with the container management service ECS allows for easier autoscaling and load balancing.